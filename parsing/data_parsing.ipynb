{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part #1: Parsing and preprocessing data\n",
    "\n",
    "By using requests library, I get html code of the wikipedia page\n",
    "\n",
    "Then, by using BeautifulSoup, table with top grossing films is being found, parsed and preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:35:39.316672Z",
     "start_time": "2025-03-03T16:35:04.203630Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "rows = table.find_all('tr')[1:]  # Skip header\n",
    "films = []\n",
    "\n",
    "BASE_WIKI_URL = \"https://en.wikipedia.org\"\n",
    "\n",
    "def parse_film_page(link):\n",
    "    response = requests.get(BASE_WIKI_URL + link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    infobox = soup.find('table', {'class': 'infobox'})\n",
    "    director = \"-\"\n",
    "    director_row = infobox.find('th', string='Directed by')\n",
    "    if director_row:\n",
    "        director = director_row.find_next('td').get_text(separator=', ', strip=True)\n",
    "\n",
    "    country = \"-\"\n",
    "    country_row = infobox.find('th', string=['Country', 'Countries'])\n",
    "    if country_row:\n",
    "        country = country_row.find_next('td').get_text(separator=', ', strip=True).split(', ')[0]\n",
    "\n",
    "    return director, country\n",
    "\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    \n",
    "    title = row.find('i').find('a')['title'] \n",
    "    title = str(title).replace('[', '').replace(']', '')\n",
    "    year = cols[3].text.strip()\n",
    "\n",
    "    link_tag = row.find('i').find('a') if row.find('i') else None\n",
    "    if link_tag:\n",
    "        film_link = link_tag['href']\n",
    "        director, country = parse_film_page(film_link)\n",
    "    else:\n",
    "        director = cols[2].text.strip().replace('\\n', ', ')\n",
    "        country = cols[4].text.strip()\n",
    "\n",
    "    revenue = cols[2].text.strip().split('$')[-1]\n",
    "    \n",
    "    revenue = revenue.replace('$', '').replace(',', '')\n",
    "    \n",
    "    films.append({\n",
    "        'title': title,\n",
    "        'release_year': year,\n",
    "        'director': director,\n",
    "        'box_office': revenue,\n",
    "        'country': country\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(films)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part #2: Saving data into the database\n",
    "\n",
    "I chose sqlite for this purpose since there is no need to download anything for its use"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:36:28.263034Z",
     "start_time": "2025-03-03T16:36:28.240452Z"
    }
   },
   "source": [
    "conn = sqlite3.connect('../data/films.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS films (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        title TEXT,\n",
    "        release_year INT,\n",
    "        director TEXT,\n",
    "        box_office REAL,\n",
    "        country TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Insert data\n",
    "df.to_sql('films', conn, if_exists='replace', index=False)\n",
    "conn.commit()\n",
    "conn.close()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part #3: Saving sata into json file\n",
    "\n",
    "Let's also save it into json"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T16:36:31.657564Z",
     "start_time": "2025-03-03T16:36:31.653054Z"
    }
   },
   "source": [
    "df.to_json('../data/films.json', orient='records', indent=2)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
